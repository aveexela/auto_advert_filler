## Постановка задачи
Цель проекта — автоматическое извлечение структурированной информации
из онлайн-объявлений (HTML-страниц и изображений) в рамках мультимодального
ML-пайплайна автозаполнения карточек товаров.

Задача включает:
- извлечение текстовых полей из HTML (название, категория, характеристики, описание);
- загрузку и базовую обработку изображений объявления;
- подготовку данных для последующего мультимодального анализа.

## Аудитория и применение
Проект ориентирован на сценарии автоматизации работы с маркетплейсами
и классифайдами (например, генерация черновиков объявлений,
подготовка датасетов для обучения моделей, ускорение модерации контента).

## Текущий статус проекта
На текущем этапе реализована часть проекта, связанная с парсингом данных:
- парсинг HTML-страниц объявлений;
- извлечение заголовка, категории, характеристик и описания;
- загрузка и сохранение изображений объявлений;

Вся реализация на данном этапе представлена в виде Jupyter Notebook.

## Архитектура текущего решения
- Jupyter Notebook содержит функции для:
  - чтения HTML-файла;
  - разбора DOM-структуры страницы;
  - извлечения текстовых и визуальных данных;
  - формирования структурированного словаря объявления.
- Данные сохраняются в файловой системе и используются для дальнейшей обработки.

## Данные
В ходе работы был собран локальный датасет объявлений с интернет-ресурса для размещения объявлений (Авито),
включающий HTML-страницы объявлений и изображения товаров.

Датасет HTML-страниц и изображений не опубликован в репозитории
по причинам защиты прав правообладателя и большого объёма данных.
В репозитории доступны агрегированные результаты парсинга
в формате `jsonl`, содержащие извлечённые структурированные поля и ссылки на объявления и изображения.

## Структура репозитория
<pre>
│   README.md
│   requirements.txt
│
├───data
│   ├───datasets
│   │       dataset_dress.jsonl
│   │       ...
│   │       dataset_trousers_woman.jsonl
│   │
│   └───links
│           links_dress.txt
│           ...
│           links_trousers_woman.txt
│
└───notebooks
        parser.ipynb
</pre>
## Запуск
Установить зависимости:
```bash
pip install -r requirements.txt
```
Проект тестировался в окружении Python 3.11, версии библиотек зафиксированы в `requirements.txt`.

## Время выполнения и ресурсы

Оценка времени выполнения парсинга для одного объявления:

- загрузка HTML-страницы: ~10 секунд;
- парсинг HTML и извлечение полей: ~10 секунд;
- загрузка изображений объявления: ~2 секунды.

Итого: ~22 секунды на одно объявление.

Замеры получены при локальном запуске,
без параллелизации и без кэширования,
в стандартном пользовательском окружении.

## Ограничения текущей реализации

* парсер ориентирован на фиксированную структуру HTML-страниц;
* отсутствует полноценный автоматический сбор данных из сети;
* мультимодальная часть (модели и обучение) не реализована на данном этапе.

## План дальнейшей работы

* формирование размеченного датасета;
* реализация мультимодального автозаполнения полей по изображениям;
* обучение и оценка моделей.



