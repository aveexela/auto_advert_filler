# Промежуточный отчет по проекту  
**Автозаполнение информации объявления по фото (мультимодальный ML-пайплайн)**

## 1. Постановка задачи

Цель проекта — построить мультимодальный ML-пайплайн для автоматического формирования черновика объявления по изображению товара.

Под черновиком понимается структурированный набор полей:
- название;
- категория;
- подкатегория;
- состояние;
- тип лота;
- текстовое описание.

Задача решается в мультимодальной постановке (изображение + текст) и ориентирована на практический сценарий: помощь пользователю при создании объявления.

---

## 2. Текущий статус проекта

На текущем этапе реализован полный end-to-end пайплайн, включающий:
- сбор и подготовку данных;
- обучение мультимодальных моделей;
- генерацию текстовых описаний.

Проект находится в промежуточной стадии: базовая ML-часть уже работает, а к защите планируется улучшение архитектуры генерации текстовых описаний для устранения характерных ошибок.

---

## 3. Пайплайн сбора и подготовки данных

### 3.1 Общая схема

Пайплайн подготовки данных реализован с упором на воспроизводимость и офлайн-обработку:

1. Ручное сохранение HTML-страниц поисковой выдачи Avito.
2. Извлечение ссылок на объявления.
3. Загрузка HTML-страниц объявлений через headless-браузер.
4. Парсинг HTML объявлений.
5. Извлечение и обработка изображений.
6. Очистка и нормализация текстов.
7. Формирование структурированного JSONL-датасета.

---

### 3.2 Парсинг объявлений

Из каждого объявления извлекаются:
- заголовок;
- текст описания (сырое и нормализованное);
- категории (по breadcrumbs);
- характеристики товара;
- ссылки на изображения.

Реализована fallback-логика для разных версий HTML-разметки Avito.

---

### 3.3 Нормализация текстов

Тексты объявлений очищаются и нормализуются:
- приводятся к нижнему регистру;
- очищаются от спецсимволов;
- исправляется псевдокириллица.

Замена латинских символов на кириллицу выполняется только для слов со смешанной письменностью, что позволяет сохранять корректные английские слова и бренды.

---

## 4. Обработка изображений

### 4.1 Извлечение изображений

Ссылки на изображения извлекаются из клиентского состояния страницы (`window.__preloadedState__`), что позволяет получать полный набор изображений независимо от DOM-разметки.

---

### 4.2 Фильтрация и дедупликация

Для изображений реализован следующий pipeline:
1. Загрузка изображений по URL.
2. Фильтрация по минимальному разрешению.
3. Вычисление perceptual hash (pHash).
4. Группировка визуально похожих изображений.
5. Выбор изображения с максимальным разрешением из каждой группы.

---

## 5. ML-часть проекта

### 5.1 Мультимодальное представление

Используется CLIP-подобная архитектура для получения совместного эмбеддингов изображений и текста.

На основе визуальных эмбеддингов реализованы:
- классификаторы категорий и атрибутов товара;
- базовая версия генерации текстового описания.

---

### 5.2 Генерация текстовых описаний (промежуточная версия)

На текущем этапе генерация описаний выполняется напрямую на основе визуальных признаков, что приводит к типичным проблемам:
- появлению шаблонных или обобщенных формулировок;
- недостаточной привязке текста к конкретным визуальным деталям;
- визуально корректным, но семантически «пустым» описаниям.

Эта версия используется как baseline и зафиксирована в репозитории.

---

### 5.3 Планируемое улучшение архитектуры генерации

К защите проекта планируется переход к двухшаговой схеме:

1. **Извлечение визуальных наблюдений**  
   Модель сначала формирует набор структурированных визуальных признаков (цвет, тип одежды, длина, фасон, наличие деталей и т.п.).

2. **Генерация текста через LLM**  
   LLM используется для генерации связного текстового описания исключительно на основе списка визуальных наблюдений, без прямого доступа к изображению.

Такой подход позволяет:
- снизить галлюцинации;
- повысить детерминированность генерации;
- улучшить соответствие текста изображению;
- разделить perception и language reasoning.

---

## 6. Формирование датасета

Финальный датасет представлен в формате JSONL. Каждая запись содержит:
- идентификатор объявления;
- пути к изображениям;
- текстовые поля;
- категории и атрибуты.

Датасет используется для:
- обучения мультимодальных моделей;
- обучения классификаторов;
- оценки качества генерации описаний.

---

## 7. Выполненные работы

- Реализован полный пайплайн парсинга Avito.
- Собран и очищен мультимодальный датасет (изображения + текст).
- Реализована обработка изображений с фильтрацией и дедупликацией.
- Реализована нормализация текстовых данных.
- Обучены базовые мультимодальные модели.
- Реализована промежуточная версия генерации описаний.

---

## 8. План дальнейших работ

До защиты проекта планируется:
1. Реализация схемы «визуальные наблюдения → LLM».
2. Улучшение качества текстовых описаний.
3. Подготовка демонстрационных примеров.

---

## 9. Репозиторий

Код проекта, ноутбуки и промежуточные результаты размещены в GitHub-репозитории. Прогресс разработки отражен через последовательные коммиты.
